# Experiment Log (실험 일지)

This is a record of an experiment to improve the separation of electric guitar and bass. 
All audio files are stored on external storage (e.g., Google Drive) and can be listened to via the link.
일렉트릭 기타와 베이스 분리 성능 향상을 위한 실험 기록입니다.
모든 오디오 파일은 외부 저장소(Google Drive 등)에 저장되어 있으며, 링크를 통해 청취 가능합니다

## Summary (요약표)
| Exp ID | 날짜 | 사용 기술 | 곡명(소스 유형) | 비고 |
| :---: | :---: | :--- | :---: | :--- |
| **001** | 25.01.09 | htdemucs_6s | 기타 베이스 분리 예제 1 (Raw) | 베이스 성공적, 기타 잡음 |
| **002** | 25.01.10 | Butterworth | 기타 베이스 분리 예제 2 (Raw) | 기타 성공적, 베이스 라인 식별 불가 |
| **003** | 25.01.12 | NMF | 기타 베이스 분리 예제 2 (Raw) | 분리 실패 |
---

## Details

###  Exp 001: 기타 베이스 분리 예제 1 (Raw Recording)
* **개요:** 기타와 베이스만 있는 트랙에서 둘을 온전히 분리할 수 있는지 검증
* **사용 음원:** 오디오 인터페이스 직렬로 직접 녹음한 일렉트릭 기타 2트랙, 일렉트릭 베이스 1트랙의 데모 (3분 30초 가량) 
* **사용 기술:**
    * Model: `htdemucs_6s`
    * Shifts: 1 (Default)
* **결과 분석:**
    * 기타만 존재하는 구간에서 기타 소리를 베이스로 착각함
    * 분리된 기타트랙의 선명도가 준수한데 비해 베이스 트랙은 볼륨의 울렁거림이 심함
* **향후 계획**
    * 더 짧은 샘플을 직접 녹음해 실험해볼 예정
    * 기타 1트랙, 베이스 1트랙으로 이루어진 음원 제작 후 실험

---
###  Exp 002: 기타 베이스 분리 예제 2 (Raw Recording)
* **개요:** Butterworth 필터를 이용해 주파수만으로 기타와 베이스를 분리할 수 있는지 검증
* **사용 음원:** Exp 001과 같은 소스에서 후반부만 잘라냄 (1분 가량) 
* **사용 기술:**
    * Frequency Filtering
      - LPF (Low Pass Filter): 낮은 주파수만 통과. → 베이스 분리용
      - HPF (High Pass Filter): 높은 주파수만 통과. → 기타 분리용
* **결과 분석:**
     * Cutoff Frequency에 따른 분리도 변화
       1) 100 ~ 200Hz
       - 베이스 트랙: 노트를 인식하기 어렵지만 기타 소리가 넘어오진 않음 -> bleeding 없음
       - 기타 트랙: 기타 소스는 일반적인 로우컷을 한 것처럼 깔끔함.
       2) 250 ~ 300Hz:
       - 베이스 트랙: 200Hz 대비좀 더 베이스의 라인을 인식하기 쉬워짐. 그러나 기타 소리가 세어나옴 bleeding 발생 250Hz 부터 미세하게 세컨기타의 타격 성분과 퍼스트 라인을 인식할 수 있음.
       - 기타 트랙: 200Hz에 비해 세컨 기타의 타격 성분이 많이 줄어들었음
* **향후 계획**
    * 더 짧은 샘플을 직접 녹음해 실험해볼 예정
    * 기타 1트랙, 베이스 1트랙으로 이루어진 음원 제작 후 실험
 
---

## Exp 003: NMF (Non-negative Matrix Factorization)

* **개요:** 단순 주파수 필터링(LPF/HPF)의 한계(주파수 대역이 겹치는 구간 분리 불가)를 극복하기 위해, 통계적 패턴 기반의 분리 알고리즘인 **NMF(비음수 행렬 분해)**를 도입하여 베이스와 기타 트랙 분리를 시도함.
* **사용 음원:** 기타 베이스 분리 예제 2 (Exp 002과 같은 소스)
* **사용 기술:**
    * Non-negative Matrix Factorization
       - 소리를 주파수 패턴($W$)과 시간 패턴($H$)의 곱으로 분해하여, 음색(Timbre)의 반복성을 기반으로 소스를 추정.
* **실험 과정:**
    * 행렬 차원 불일치 (Shape Mismatch) 오류 해결
       - 문제: 분해된 결과물 재조합 시 `ValueError` 발생.
       - 원인: `librosa.decompose` 수행 후 $W$(주파수 특징)와 $H$(시간 특징) 중 하나만 추출하여 계산함. 소리의 재구성을 위해서는 두 행렬의 외적(Outer Product)이 필요함.
       - 해결: $W, H$를 모두 반환받아 $W \times H$ 연산을 통해 원본 스펙트로그램 차원과 일치시킴.
    * `n_fft` 조정:1024, 2048(Default), 4096, 8192로 변경하며 주파수 해상도에 따른 분리도 관찰.
       - 유의미한 성능 향상 없음
    * Masking 기법 변환: Soft Masking vs Hard Masking 비교 실험.
       - 분리 성능 저하 발생
* **결과 분석:**
기대와 달리 기존 Frequency Filtering 방식보다 분리도가 하락함.
    * Severe Bleeding (블리딩 현상):
       - 기타 트랙에 베이스의 저음이, 베이스 트랙에 기타의 고음이 다수 혼입됨.
       - Hard Masking 적용 시 고주파 노이즈와 볼륨 울렁거림(Artifacts)이 심화됨.
    *Mel-Spectrogram 시각화 분석:
       - 시각화 결과, 두 트랙 모두 특정 주파수 대역이 깨끗하게 소거되지 않고 에너지가 잔존함을 확인.
       - 기타 트랙에서도 상당한 저음역대를 확인 가능, 베이스 트랙에서도 고음역 에너지 확인
       - 곡의 중반부(약 18초), 리드 기타가 솔로를 연주하며 한 옥타브 위로 올라가는 시점부터 분리 정도가 심화됨. 악기의 분리가 아닌 트랙 자체의 분리
* **향후 계획**
    * 딥러닝(Deep Learning) 기반의 비선형 모델(U-Net, Demucs 등)을 도입하여 Spectrogram의 패턴을 학습시키는 방식으로 전환 예정.

